{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "68e81057",
   "metadata": {},
   "source": [
    "# Sentiment Analysis with RNN example"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25d0b1a2",
   "metadata": {},
   "source": [
    "### Step 1. Load data and exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "657b5e72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: 25000. Test size: 25000\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import imdb\n",
    "\n",
    "# Load the data set into train and test sets\n",
    "vocabulary_size = 5000\n",
    "(X_train, y_train), (X_test, y_test) = imdb.load_data(num_words=vocabulary_size)\n",
    "print(f'Train size: {len(X_train)}. Test size: {len(X_test)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "89d2638c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Review ---\n",
      "[1, 4, 2, 716, 4, 65, 7, 4, 689, 4367, 2, 2343, 4804, 2, 2, 2, 2, 2315, 2, 2, 2, 2, 4, 2, 628, 2, 37, 9, 150, 4, 2, 4069, 11, 2909, 4, 2, 847, 313, 6, 176, 2, 9, 2, 138, 9, 4434, 19, 4, 96, 183, 26, 4, 192, 15, 27, 2, 799, 2, 2, 588, 84, 11, 4, 3231, 152, 339, 2, 42, 4869, 2, 2, 345, 4804, 2, 142, 43, 218, 208, 54, 29, 853, 659, 46, 4, 882, 183, 80, 115, 30, 4, 172, 174, 10, 10, 1001, 398, 1001, 1055, 526, 34, 3717, 2, 2, 2, 17, 4, 2, 1094, 871, 64, 85, 22, 2030, 1109, 38, 230, 9, 4, 4324, 2, 251, 2, 1034, 195, 301, 14, 16, 31, 7, 4, 2, 8, 783, 2, 33, 4, 2945, 103, 465, 2, 42, 845, 45, 446, 11, 1895, 19, 184, 76, 32, 4, 2, 207, 110, 13, 197, 4, 2, 16, 601, 964, 2152, 595, 13, 258, 4, 1730, 66, 338, 55, 2, 4, 550, 728, 65, 1196, 8, 1839, 61, 1546, 42, 2, 61, 602, 120, 45, 2, 6, 320, 786, 99, 196, 2, 786, 2, 4, 225, 4, 373, 1009, 33, 4, 130, 63, 69, 72, 1104, 46, 1292, 225, 14, 66, 194, 2, 1703, 56, 8, 803, 1004, 6, 2, 155, 11, 4, 2, 3231, 45, 853, 2029, 8, 30, 6, 117, 430, 19, 6, 2, 9, 15, 66, 424, 8, 2337, 178, 9, 15, 66, 424, 8, 1465, 178, 9, 15, 66, 142, 15, 9, 424, 8, 28, 178, 662, 44, 12, 17, 4, 130, 898, 1686, 9, 6, 2, 267, 185, 430, 4, 118, 2, 277, 15, 4, 1188, 100, 216, 56, 19, 4, 357, 114, 2, 367, 45, 115, 93, 788, 121, 4, 2, 79, 32, 68, 278, 39, 8, 818, 162, 4165, 237, 600, 7, 98, 306, 8, 157, 549, 628, 11, 6, 2, 13, 824, 15, 4104, 76, 42, 138, 36, 774, 77, 1059, 159, 150, 4, 229, 497, 8, 1493, 11, 175, 251, 453, 19, 2, 189, 12, 43, 127, 6, 394, 292, 7, 2, 4, 107, 8, 4, 2826, 15, 1082, 1251, 9, 906, 42, 1134, 6, 66, 78, 22, 15, 13, 244, 2519, 8, 135, 233, 52, 44, 10, 10, 466, 112, 398, 526, 34, 4, 1572, 4413, 2, 1094, 225, 57, 599, 133, 225, 6, 227, 7, 541, 4323, 6, 171, 139, 7, 539, 2, 56, 11, 6, 3231, 21, 164, 25, 426, 81, 33, 344, 624, 19, 6, 4617, 7, 2, 2, 6, 2, 4, 22, 9, 1082, 629, 237, 45, 188, 6, 55, 655, 707, 2, 956, 225, 1456, 841, 42, 1310, 225, 6, 2493, 1467, 2, 2828, 21, 4, 2, 9, 364, 23, 4, 2228, 2407, 225, 24, 76, 133, 18, 4, 189, 2293, 10, 10, 814, 11, 2, 11, 2642, 14, 47, 15, 682, 364, 352, 168, 44, 12, 45, 24, 913, 93, 21, 247, 2441, 4, 116, 34, 35, 1859, 8, 72, 177, 9, 164, 8, 901, 344, 44, 13, 191, 135, 13, 126, 421, 233, 18, 259, 10, 10, 4, 2, 2, 4, 2, 3074, 7, 112, 199, 753, 357, 39, 63, 12, 115, 2, 763, 8, 15, 35, 3282, 1523, 65, 57, 599, 6, 1916, 277, 1730, 37, 25, 92, 202, 6, 2, 44, 25, 28, 6, 22, 15, 122, 24, 4171, 72, 33, 32]\n",
      "--- Label ---\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "# Example of a review and a corresponding label\n",
    "print(\"--- Review ---\")\n",
    "print(X_train[7])\n",
    "print(\"--- Label ---\")\n",
    "print(y_train[7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2730f8f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The maximum sequence length is: 2494\n"
     ]
    }
   ],
   "source": [
    "# Define translation dictionaries\n",
    "word2id = imdb.get_word_index()\n",
    "id2word = {i: word for word, i in word2id.items()}\n",
    "\n",
    "# Maximum sequence length\n",
    "print(f'The maximum sequence length is: {max(len(x) for x in X_train)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92d472ea",
   "metadata": {},
   "source": [
    "### Step 2. Padding seqences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "59539c7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing import sequence\n",
    "from tensorflow.keras.utils import pad_sequences\n",
    "\n",
    "max_words = 500\n",
    "\n",
    "X_train = pad_sequences(X_train, maxlen = max_words)\n",
    "X_test = pad_sequences(X_test, maxlen = max_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ebb95b8",
   "metadata": {},
   "source": [
    "### Step 3. RNN model design"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e4f7d509",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_1 (Embedding)     (None, 500, 128)          640000    \n",
      "                                                                 \n",
      " lstm_2 (LSTM)               (None, 500, 64)           49408     \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 500, 64)           0         \n",
      "                                                                 \n",
      " lstm_3 (LSTM)               (None, 64)                33024     \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 128)               8320      \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 1)                 129       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 730,881\n",
      "Trainable params: 730,881\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Embedding, LSTM, Dense, Dropout\n",
    "\n",
    "# Basel\n",
    "model = Sequential([\n",
    "    Embedding(input_dim=vocabulary_size, output_dim=128, input_length=max_words),\n",
    "    LSTM(units = 64, return_sequences = True),\n",
    "    Dropout(0.2),\n",
    "    LSTM(units = 64),\n",
    "    Dense(128),\n",
    "    Dense(1, activation = 'sigmoid')\n",
    "])\n",
    "\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d6968ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
